---
title: Integrate AWS account with New Relic for log forwarding
tags:
  - Integrations
  - Log Forwarding
  - S3 log forwarding
metaDescription: How to integrate AWS account with New Relic for log forwarding.

freshnessValidatedDate: never
---

Forward your AWS logs into New Relic to have enhanced visibility into system performance, enable the early detection of issues, and take informed decisions. Our log management solution helps you enhance your team's operational efficiency while maintaining security and compliance.


By setting up an AWS integration with a CloudFormation template via New Relic, you can configure and ingest logs and metrics into New Relic. You can also set up integration for both logs and metrics together using a single CloudFormation template.

<Callout variant="tip">
For more details on how to send New Relic metrics data via Terraform or API Polling, refer [Amazon CloudWatch Metric Streams](/install/aws-cloudwatch/).
</Callout>

## AWS log forwarding capabilities and methods [#log-forwarding-capabilities-methods]


You can forward logs from AWS S3 and CloudWatch to New Relic using the following methods. Depending on your needs, you can select the appropriate one during configuration setup:

* **Amazon S3 via New Relic Lambda function**: Provides high control over data transformation before forwarding from S3.
* **Amazon CloudWatch via New Relic Lambda function**: Provides high control over data transformation before forwarding from CloudWatch.
* **Amazon CloudWatch via Amazon Kinesis Data Firehose**: Ideal for direct and high-volume data streaming from CloudWatch.

## Prerequisites [#prerequisites-aws-integration]

Before you strat integrating the AWS account with New Relic, ensure you have the following:
* An AWS account with [permissions](https://docs.aws.amazon.com/ARG/latest/userguide/gettingstarted-prereqs-permissions.html) to deploy new AWS resources and [IAM roles](https://docs.aws.amazon.com/IAM/latest/UserGuide/id_roles.html)
* A New Relic account with [log forwarding setup](/docs/accounts/accounts-billing/new-relic-one-user-management/user-permissions/#logs)
* A New Relic [license key](https://one.newrelic.com/api-keys)

## AWS account integration for log forwarding [#log-forwarding-capabilities-methods]

Follow these steps to integrate your AWS account with New Relic for log forwarding.

<Steps>
<Step>
### Set up AWS integration in New Relic [#set-up-aws-integration]
On New Relic, set up the AWS data type and log forwarding path to ingest data from AWS.
1. Log in to [New Relic](https://one.newrelic.com/).
2. Navigate to <DNT>**+ Integrations & Agents**</DNT>.
3. Select your New Relic account from the <DNT>**Account**</DNT> drop-down.
4. Search and select <DNT>**Integrate your AWS account**</DNT> from the <DNT>**All**</DNT> tab.
5. Select <DNT>**Logs**</DNT> as the data type to ingest, and continue.
6. Select <DNT>**Automate AWS with CloudFoundation (Recommended)**</DNT> as the setup method and continue. This is the only option available for log integration.
7. Depending upon your AWS setup, choose any of the following log interation path:
   * <DNT>**S3 via Lambda**</DNT>: Logs from Amazon S3 bucket to New Relic via AWS Lambda function.
   * <DNT>**CloudWatch via Firehose or Lambda > Logs from  Cloudwatch via Firehose**</DNT>: CloudWatch to New Relic via Kinesis Data Firehose.
   * <DNT>**CloudWatch via Firehose or Lambda > Logs from  Cloudwatch via Lambda**</DNT>: CloudWatch to New Relic via AWS Lambda function.
</Step>

<Step>
### Configure log forwarding [#configure-log-forwarding]
Configure triggers to specify which log data should come to New Relic, and select an endpoint where the logs will reside.

1. Specify the data sources. You can add upto 40 S3 buckets or log groups for one AWS account integration.
   * <DNT>**S3**</DNT>: Enter the S3 bucket name, and prefix if any. You can select <DNT>**+ S3 bucket**</DNT> to add multiple S3 buckets.
   * <DNT>**CloudWatch**</DNT>: Enter the log group name, and filter if any. You can select <DNT>**+ Add log group**</DNT> to add multiple log groups.
2. Check the endpoint for storing the logs, and change if required. The default endpoint is set as per your New Relic account region. 
3. Add custom attributes to organize your logs and make them easier to search, filter, analyze, and parse.
4. Click <DNT>**Continue**</DNT>.
</Step>

<Step>
## Connect your AWS account with New Relic [#connect-aws-account]
Create a CloudFormation Stack to ingest data into New Relic.

1. Provide a unique name for your stack.
2. If you do not have a New Relic license key, select <DNT>**Create a new key > Copy key**</DNT>.
3. Select <DNT>**Launch your Cloudformation in AWS**</DNT>. AWS Cloud Console opens with the <DNT>**Quick create stack**</DNT> form.
4. Paste the New Relic license key in the <DNT>**New Relic Ingest License Key**</DNT> field. The fields auto-populate the data you have entered in New Relic. You can further change the values here, if required.
5. Read through the <DNT>**Launch your Cloudformation in AWS**</DNT> and acknowledge for the necessary capabilities.
6. Select <DNT>**Create stack**</DNT>. It may take several minutes to create the new stack.
7. Go to the <DNT>**Connect your data AWS Account**</DNT> page in the New Relic platform instance.
8. Continue with the licence key:
   * If you are using an existing license key, paste it in <DNT>**License key**</DNT> and continue.
   * If you have created a new key, just select <DNT>**Continue**</DNT>. 
9. Select <DNT>**See your data**</DNT>. The logs start appearing in New Relic.
</Step>
</Steps>

## Log forwarding restrictions [#log-forwarding-restrictions]

Following are the restrictions New Relic has with AWS integration for log forwarding, depending upon the method you select.

### For ingesting AWS logs from S3 [#s3-restrictions]
* The log file size should be less that 80 mb.
* The size of a single log line should be less than 8 mb.
* Log line size between 1mb and 8mb will be split into multiple messages and forwarded to New Relic.
* New Relic currently doesn't support Client Json or log line parsing.
* New Relic currently supports only `Gzip` and `Bzip2` compression formats for log files. It process files in other compressed format as uncompressed files.
### For ingesting logs from CloudWatch [#cloudwatch-restrictions]
* New Relic currently doesn't support client Json or log line parsing.
* New Relic currently supports only [Lambda layers](https://github.com/newrelic/newrelic-lambda-layers) for parsing logic.

## Log forward troubleshooting [#log-forward-troubleshooting]

It's possible that you may get issues with log ingestion to New Relic after configuration. This page will help you to resolve the possible errors you may have.

### Failing to create a stack [#stack-failure]
For a stack failure, do the following checks in your AWS account:
1. Ensure that the selected IAM role (if you have selected during CloudFormation stack creation) has sufficient permissions to create IAM roles. If you have not selected IAM role, make sure your account has enough permissions.
2. If the failure message appears as **Resource type `resource-type` with identifier `resource-identifier` already exists**, delete or rename the existing resources with that name, and retry.
3. Check the output of the nested CloudFormation stacks to identify possible errors.
4. Ensure that the selected S3 buckets don’t have event notifications on any of the object creating events.
5. Ensure that the selected CloudWatch groups don’t have any other similar subscription filters.

### Failing to delete a stack [#stack-delete]
If you are not able to delete a stake, perform the follwing steps in your AWS account:
1. Identify the S3 buckets created by the stack (For example, the S3 bucket created for Firehose error logs).
2. Archive the available content, and make it empty.
3. Retry deleting the stack.

### Logs not flowing from Cloudwatch via Lambda [#Cloudwatch-lambda-error]
If the logs are not appearing for a <DNT>**Cloudwatch via Lambda**</DNT> integration setup, do the following checks in your AWS account:
1. Navigate to <DNT>**CloudFormation stack > Resources**</DNT> and find the resource with Logical Id `NewRelicLogsLicenseKeySecret` and validate the New Relic Ingest License Key.
2. Check the <DNT>**CloudWatch logs**</DNT> for the Lambda function to further debug.
3. Set the `DEBUG_MODE` parameter to `true` in the Lambda function’s environment variables to get debug logs. Navigate to <DNT>**CloudFormation Stack > Resources > NewRelicServerlessLogForwarder (Lambda Function) > Configuration > Environment Variables**</DNT>.
4. Check the <DNT>**DLQ resource**</DNT> in the CloudFormation stack to see if the event was a genuine failure. Navigate to <DNT>**CloudFormation Stack > Resources > NewRelicLogForwarderDLQ**</DNT>, or search for your <DNT>**DLQ**</DNT> in AWS SQS.
5. Ensure the New Relic region and the Ingest License Key provided to the Lambda function or Firehose are correctly matched (For example, if the New Relic region is EU, provide a New Relic Ingest License Key from the EU region).
6. Check if `NewRelicServerlessLogForwarder` has the <DNT>**CloudWatch trigger**</DNT>. Check the output of the nested CloudFormation stacks to find this issue.
### Logs not flowing from S3 via Lambda [#s3-lambda-error]
If the logs are not appearing for an <DNT>**S3 via Lambda**</DNT> integration setup, do the following checks in your AWS account:
1. Follow the steps in [Logs not flowing from Cloudwatch via Lambda](/aws-logs/#Cloudwatch-lambda-error).
2. Ensure that the S3 files are adhering to the [log forwarding restrictions](/install/aws-logs/aws_services/log-forwarding-limitations).
3. Check if `NewRelicServerlessLogForwarder` has the <DNT>**S3 trigger**</DNT>. Check the output of the nested CloudFormation stacks to find this issue.
### Logs not flowing from Cloudwatch via Firehose [#Cloudwatch-firehose-error]
If the logs are not appearing for a <DNT>**Cloudwatch via Lambda**</DNT> integration setup, do the following checks in your AWS account:
1. Update your API key to the correct Ingest License key. Navigate to <DNT>**Amazon Data Firehose > Firehose streams > your-stream > Edit destination settings**</DNT>.
2. Verify the <DNT>**endpoint**</DNT>.
3. Check the <DNT>**S3 logs**</DNT> or <DNT>**CloudWatch error logs**</DNT>.
### Custom attributes not appearing [#attribut-not-appearing]
If the custom attributes for the logs are not appearing in New Relic, do the following checks in your AWS account:
* For <DNT>**S3 via Lambda**</DNT> or <DNT>**CloudWatch via Lambda**</DNT>, ensure that the `CUSTOM_META_DATA` environment variable is set and a valid JSON value is available.
* For <DNT>**CloudWatch via Firehose**</DNT>, ensure that your key-value pairs are present under <DNT>**Parameters**</DNT>.
* For all cases, ensure that your key names don’t overlap with the forbidden keywords mentioned in AWS logs in context.

## Points to consider while upgrading lambda [#lambda-upgrade-considerations]
When upgrading from the old Lambda to the new unified Lambda, consider the following important points to ensure a smooth transition:

* **Handling existing Lambdas**
    The old setup may have separate Lambdas for S3 and CloudWatch log ingestion. Before migrating to the new unified Lambda, either delete these old Lambdas or manually remove their triggers. This step is crucial to prevent any conflicts or duplication of data processing.
* **Avoiding trigger or subscription duplication**
    Ensure that you do not create duplicate triggers or subscriptions when using both <DNT>**S3 Via Lambda**</DNT> and <DNT>**CloudWatch Via Lambda**</DNT>.
* **Monitoring service limits**
    Be aware of the service limits on reading logs from S3 and CloudWatch, as exceeding these limits can cause inconsistencies in the data reaching New Relic.


